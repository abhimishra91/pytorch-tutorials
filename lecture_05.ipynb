{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 05:\n",
    "\n",
    "**Linear Regression PyTorch way**\n",
    "\n",
    "There is a rythm to the pytorch programs\n",
    "\n",
    "* Model and network\n",
    "    - Forward pass\n",
    "* Loss and Optimizer\n",
    "* Training loop\n",
    "\n",
    "\n",
    "We will use the same linear regression example as before for this lecture and use pytorch natively for all the coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0],[3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0],[6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model network and forward pass\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate 2 nn.linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1) # One data in and one out for x and y\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In forward function we accept the input variable and we return variable for the output\n",
    "        We can use the modules defined in the constructor and arbitary operations\n",
    "        on the variable as well\"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "# Our model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer.\n",
    "# model.parameters() automatically calcuated the gradient for all the weights in the network\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average = False)\n",
    "optimum = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.000493427854962647\n",
      "Epoch: 1, Loss:  0.00048634305130690336\n",
      "Epoch: 2, Loss:  0.00047935411566868424\n",
      "Epoch: 3, Loss:  0.00047246244503185153\n",
      "Epoch: 4, Loss:  0.0004656784294638783\n",
      "Epoch: 5, Loss:  0.0004589696181938052\n",
      "Epoch: 6, Loss:  0.0004523824609350413\n",
      "Epoch: 7, Loss:  0.0004458907642401755\n",
      "Epoch: 8, Loss:  0.0004394740972202271\n",
      "Epoch: 9, Loss:  0.0004331583040766418\n",
      "Epoch: 10, Loss:  0.00042693031718954444\n",
      "Epoch: 11, Loss:  0.00042080465937033296\n",
      "Epoch: 12, Loss:  0.00041475644684396684\n",
      "Epoch: 13, Loss:  0.00040878489380702376\n",
      "Epoch: 14, Loss:  0.00040291156619787216\n",
      "Epoch: 15, Loss:  0.0003971316618844867\n",
      "Epoch: 16, Loss:  0.00039141540764831007\n",
      "Epoch: 17, Loss:  0.0003857953997794539\n",
      "Epoch: 18, Loss:  0.00038024436798878014\n",
      "Epoch: 19, Loss:  0.00037479097954928875\n",
      "Epoch: 20, Loss:  0.00036940042627975345\n",
      "Epoch: 21, Loss:  0.0003640844370238483\n",
      "Epoch: 22, Loss:  0.00035885433317162097\n",
      "Epoch: 23, Loss:  0.0003536948934197426\n",
      "Epoch: 24, Loss:  0.0003486151108518243\n",
      "Epoch: 25, Loss:  0.0003436130646150559\n",
      "Epoch: 26, Loss:  0.0003386674798093736\n",
      "Epoch: 27, Loss:  0.00033380769309587777\n",
      "Epoch: 28, Loss:  0.0003290083259344101\n",
      "Epoch: 29, Loss:  0.00032428139820694923\n",
      "Epoch: 30, Loss:  0.00031960842898115516\n",
      "Epoch: 31, Loss:  0.00031501270132139325\n",
      "Epoch: 32, Loss:  0.00031049229437485337\n",
      "Epoch: 33, Loss:  0.00030603198683820665\n",
      "Epoch: 34, Loss:  0.0003016302362084389\n",
      "Epoch: 35, Loss:  0.00029729443485848606\n",
      "Epoch: 36, Loss:  0.0002930318296421319\n",
      "Epoch: 37, Loss:  0.00028881384059786797\n",
      "Epoch: 38, Loss:  0.0002846646821126342\n",
      "Epoch: 39, Loss:  0.00028057279996573925\n",
      "Epoch: 40, Loss:  0.0002765395911410451\n",
      "Epoch: 41, Loss:  0.00027256819885224104\n",
      "Epoch: 42, Loss:  0.00026865125983022153\n",
      "Epoch: 43, Loss:  0.0002647844376042485\n",
      "Epoch: 44, Loss:  0.0002609850780572742\n",
      "Epoch: 45, Loss:  0.00025722902501001954\n",
      "Epoch: 46, Loss:  0.000253535428782925\n",
      "Epoch: 47, Loss:  0.0002498896501492709\n",
      "Epoch: 48, Loss:  0.0002462957927491516\n",
      "Epoch: 49, Loss:  0.00024276424665004015\n",
      "Epoch: 50, Loss:  0.00023927078291308135\n",
      "Epoch: 51, Loss:  0.0002358347992412746\n",
      "Epoch: 52, Loss:  0.00023244312615133822\n",
      "Epoch: 53, Loss:  0.0002291033451911062\n",
      "Epoch: 54, Loss:  0.00022580692893825471\n",
      "Epoch: 55, Loss:  0.00022256042575463653\n",
      "Epoch: 56, Loss:  0.000219370995182544\n",
      "Epoch: 57, Loss:  0.0002162097516702488\n",
      "Epoch: 58, Loss:  0.0002131020009983331\n",
      "Epoch: 59, Loss:  0.00021004454174544662\n",
      "Epoch: 60, Loss:  0.00020702675101347268\n",
      "Epoch: 61, Loss:  0.0002040490653598681\n",
      "Epoch: 62, Loss:  0.0002011168544413522\n",
      "Epoch: 63, Loss:  0.00019823206821456552\n",
      "Epoch: 64, Loss:  0.00019538355991244316\n",
      "Epoch: 65, Loss:  0.00019257667008787394\n",
      "Epoch: 66, Loss:  0.00018980208551511168\n",
      "Epoch: 67, Loss:  0.00018707069102674723\n",
      "Epoch: 68, Loss:  0.0001843883073888719\n",
      "Epoch: 69, Loss:  0.00018173549324274063\n",
      "Epoch: 70, Loss:  0.00017912212933879346\n",
      "Epoch: 71, Loss:  0.00017654933617450297\n",
      "Epoch: 72, Loss:  0.000174012006027624\n",
      "Epoch: 73, Loss:  0.0001715158869046718\n",
      "Epoch: 74, Loss:  0.0001690446079010144\n",
      "Epoch: 75, Loss:  0.0001666130410740152\n",
      "Epoch: 76, Loss:  0.00016422067710664123\n",
      "Epoch: 77, Loss:  0.00016185821732506156\n",
      "Epoch: 78, Loss:  0.00015953781257849187\n",
      "Epoch: 79, Loss:  0.00015724146214779466\n",
      "Epoch: 80, Loss:  0.00015498421271331608\n",
      "Epoch: 81, Loss:  0.0001527576387161389\n",
      "Epoch: 82, Loss:  0.0001505643012933433\n",
      "Epoch: 83, Loss:  0.00014839674986433238\n",
      "Epoch: 84, Loss:  0.00014626598567701876\n",
      "Epoch: 85, Loss:  0.00014416183694265783\n",
      "Epoch: 86, Loss:  0.0001420860644429922\n",
      "Epoch: 87, Loss:  0.00014004806871525943\n",
      "Epoch: 88, Loss:  0.0001380343601340428\n",
      "Epoch: 89, Loss:  0.00013605151616502553\n",
      "Epoch: 90, Loss:  0.00013410118117462844\n",
      "Epoch: 91, Loss:  0.00013217095693107694\n",
      "Epoch: 92, Loss:  0.00013027130626142025\n",
      "Epoch: 93, Loss:  0.00012840254930779338\n",
      "Epoch: 94, Loss:  0.00012654860620386899\n",
      "Epoch: 95, Loss:  0.00012472760863602161\n",
      "Epoch: 96, Loss:  0.00012294366024434566\n",
      "Epoch: 97, Loss:  0.0001211712951771915\n",
      "Epoch: 98, Loss:  0.00011943148274440318\n",
      "Epoch: 99, Loss:  0.00011770993296522647\n",
      "Predict (after training) 4 7.987527847290039\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range (100):\n",
    "    # Using forward pass to calcuate the prediction\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # Compute and print the loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    \n",
    "    # Making the gradients zero and then doing a backward pass to calcuate\n",
    "    # And then update the weights\n",
    "    optimum.zero_grad()\n",
    "    loss.backward()\n",
    "    optimum.step()\n",
    "    \n",
    "    \n",
    "# After training\n",
    "new_val = torch.Tensor([4.0])\n",
    "print('Predict (after training)', 4, model.forward(new_val).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
