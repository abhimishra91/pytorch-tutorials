{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitfastaiconda149f4ca18fae45818735beadf08062d0",
   "language": "python",
   "display_name": "Python 3.7.6 64-bit ('fastai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 10:\n",
    "\n",
    "\n",
    "* We are going to use **_CNN_** in this Lecture\n",
    "* The dataset to be used is the **_MINST Dataset_** given by pytorch package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the stock libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CUDA environment\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the model\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader for the input to the model\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n  (l1): Linear(in_features=320, out_features=10, bias=True)\n  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Model\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    ## Initiatize\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.l1 = torch.nn.Linear(320, 10)\n",
    "\n",
    "        self.max = torch.nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "    ## Forward\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = torch.nn.functional.relu(self.max(self.conv1(x)))\n",
    "        x = torch.nn.functional.relu(self.max(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.l1(x)\n",
    "        return torch.nn.functional.log_softmax(x)\n",
    "\n",
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimus = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code for training\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predict = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(predict, labels)\n",
    "        if _%500 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "        # zero optimus,back propagation, update optimus\n",
    "        optimus.zero_grad()\n",
    "        loss.backward()\n",
    "        optimus.step()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for the validation step\n",
    "\n",
    "def valid(test_dataloader):\n",
    "    model.eval()\n",
    "    total=0; n_correct =0 \n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(test_dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if _%500 == 0:\n",
    "                print(f'Validation completed for {_} samples')\n",
    "\n",
    "            predict = model(inputs)\n",
    "            total += labels.size(0)\n",
    "            big_val, big_idx = torch.max(predict.data, dim=1)\n",
    "            n_correct += (big_idx==labels).sum().item()\n",
    "\n",
    "    return (n_correct*100)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training\n",
      "Epoch: 0, Loss:  2.313748598098755\n",
      "Epoch: 0, Loss:  0.3788803517818451\n",
      "Epoch: 0, Loss:  0.35306981205940247\n",
      "Epoch: 0, Loss:  0.15131986141204834\n",
      "Epoch: 1, Loss:  0.48513269424438477\n",
      "Epoch: 1, Loss:  0.13334602117538452\n",
      "Epoch: 1, Loss:  0.1520206332206726\n",
      "Epoch: 1, Loss:  0.08754238486289978\n",
      "Training Completed\n",
      "+++++++++++++++++=================+++++++++++++++++=================++++++++++++++++\n",
      "Starting the testing\n",
      "Validation completed for 0 samples\n",
      "The accuracy of the model is: 96.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\Anaconda3\\envs\\fastai\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Calling the training function\n",
    "\n",
    "print('Starting the training')\n",
    "\n",
    "for epoch in range(0,2):\n",
    "    train(epoch)\n",
    "\n",
    "print('Training Completed')\n",
    "\n",
    "print('+++++++++++++++++=================+++++++++++++++++=================++++++++++++++++')\n",
    "\n",
    "print('Starting the testing')\n",
    "accu = valid(test_dataloader)\n",
    "print(f'The accuracy of the model is: {accu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}