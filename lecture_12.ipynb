{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitfastaiconda149f4ca18fae45818735beadf08062d0",
   "display_name": "Python 3.7.6 64-bit ('fastai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 12: \n",
    "\n",
    "* We are going to do RNN in this session. \n",
    "* Very powerful concept. Hidden state of one cell is used as an input for another cell in addition to the original input. \n",
    "\n",
    "\n",
    "For `RNN` the arguments that are passed are:\n",
    "\n",
    "* `input_size`\n",
    "* `hidden_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stock libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: \n",
    "\n",
    "* Feeding `H E L L O` to RNN\n",
    "* We will use 1 hot vector encoding for this\n",
    "\n",
    "\n",
    "* $h = [1,0,0,0]$\n",
    "* $e = [0,1,0,0]$\n",
    "* $l = [0,0,1,0]$\n",
    "* $o = [0,0,0,1]$\n",
    "\n",
    "This is feeded to the network/cell one by one. Hence,\n",
    "* `input size = 4`\n",
    "* `hidden size = 2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input size torch.Size([1, 1, 4])\nOut tensor([[[0.6362, 0.4687]]])\nType torch.float32\nSize torch.Size([1, 1, 2])\nHidden tensor([[[0.6362, 0.4687]]])\n"
    }
   ],
   "source": [
    "# Create an RNN cell with the desited input size and hidden size\n",
    "\n",
    "cell = torch.nn.RNN(input_size=4, hidden_size=2,batch_first=True)\n",
    "\n",
    "# Creating the one letter input\n",
    "h = [1,0,0,0]\n",
    "inputs = torch.Tensor([[h]])\n",
    "print('Input size', inputs.size())\n",
    "\n",
    "# initialize the hidden state\n",
    "# (num_layers*num_directios, batch, hidden_size)\n",
    "\n",
    "hidden = torch.Tensor(torch.rand(1,1,2))\n",
    "\n",
    "# Feed one element at a time\n",
    "# after each step, hidden contains the hidden state\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print('Out', out.data)\n",
    "print('Type', out.dtype)\n",
    "print('Size',out.size())\n",
    "print('Hidden', hidden.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input size torch.Size([1, 5, 4])\nOut tensor([[[ 0.4185, -0.8764],\n         [ 0.5675,  0.2853],\n         [ 0.3233, -0.7229],\n         [ 0.2798, -0.4977],\n         [ 0.2200, -0.6902]]])\nType torch.float32\nSize torch.Size([1, 5, 2])\nHidden tensor([[[ 0.2200, -0.6902]]])\n"
    }
   ],
   "source": [
    "# Create an RNN cell with the desited input size and hidden size, this time we are entering more than 1 charecter\n",
    "\n",
    "cell = torch.nn.RNN(input_size=4, hidden_size=2,batch_first=True)\n",
    "\n",
    "# hidden_size =2\n",
    "# batch_size=1\n",
    "# sequence_length=5\n",
    "\n",
    "inputs = torch.Tensor([[h,e,l,l,o]])\n",
    "print('Input size', inputs.size())\n",
    "\n",
    "# initialize the hidden state\n",
    "# (num_layers*num_directios, batch, hidden_size)\n",
    "\n",
    "hidden = torch.Tensor(torch.rand(1,1,2))\n",
    "\n",
    "# Feed one element at a time\n",
    "# after each step, hidden contains the hidden state\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print('Out', out.data)\n",
    "print('Type', out.dtype)\n",
    "print('Size',out.size())\n",
    "print('Hidden', hidden.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input size torch.Size([3, 5, 4])\nOut tensor([[[-0.5312, -0.0883],\n         [ 0.6064, -0.6325],\n         [ 0.3647, -0.7075],\n         [ 0.3591, -0.7897],\n         [-0.5652, -0.8731]],\n\n        [[ 0.7213,  0.2784],\n         [ 0.6125, -0.4499],\n         [ 0.4220, -0.6717],\n         [-0.5384, -0.8517],\n         [ 0.3825, -0.9386]],\n\n        [[ 0.7266, -0.2211],\n         [ 0.4819, -0.5763],\n         [ 0.4050, -0.2343],\n         [ 0.5114, -0.1682],\n         [ 0.5114, -0.6541]]])\nType torch.float32\nSize torch.Size([3, 5, 2])\nHidden tensor([[[-0.5652, -0.8731],\n         [ 0.3825, -0.9386],\n         [ 0.5114, -0.6541]]])\n"
    }
   ],
   "source": [
    "# Create an RNN cell with the desited input size and hidden size, this time we are entering more than 1 word. \n",
    "\n",
    "# hidden_size =2\n",
    "# batch_size=2\n",
    "# sequence_length=5\n",
    "\n",
    "cell = torch.nn.RNN(input_size=4, hidden_size=2,batch_first=True)\n",
    "\n",
    "# Creating the one letter input\n",
    "inputs = torch.Tensor(\n",
    "    [\n",
    "        [h,e,l,l,o],\n",
    "        [e,l,l,o,l],\n",
    "        [l,l,e,e,l]\n",
    "    ]\n",
    "    )\n",
    "print('Input size', inputs.size())\n",
    "\n",
    "# initialize the hidden state\n",
    "# (num_layers*num_directios, batch, hidden_size)\n",
    "\n",
    "hidden = torch.Tensor(torch.rand(1,3,2))\n",
    "\n",
    "# Feed one element at a time\n",
    "# after each step, hidden contains the hidden state\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print('Out', out.data)\n",
    "print('Type', out.dtype)\n",
    "print('Size',out.size())\n",
    "print('Hidden', hidden.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2:\n",
    "\n",
    "* We will be feeding the string `hihell` to the network such that it gives us the output `ihello` basically predicting the next charter\n",
    "\n",
    "* This is a sequence classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a project to convert hihell -> ihello\n",
    "\n",
    "# Data prepration\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "\n",
    "x_data = [0,1,0,2,3,3] #hihell\n",
    "\n",
    "x_data = [[0, 1, 0, 2, 3, 3]]   # hihell\n",
    "x_one_hot = [[[1, 0, 0, 0, 0],   # h 0\n",
    "             [0, 1, 0, 0, 0],    # i 1\n",
    "             [1, 0, 0, 0, 0],    # h 0\n",
    "             [0, 0, 1, 0, 0],    # e 2\n",
    "             [0, 0, 0, 1, 0],    # l 3\n",
    "             [0, 0, 0, 1, 0]]]   # l 3\n",
    "\n",
    "y_data = [1, 0, 2, 3, 3, 4]    # ihello\n",
    "\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot)\n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_classes =5\n",
    "input_size =5 # One-hot size\n",
    "hidden_size = 5 # output from the cell\n",
    "batch_size=1 # one sentence\n",
    "sequence_length=6\n",
    "num_layers=1 # one layer run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model(\n  (rnn): RNN(5, 5, batch_first=True)\n)\n"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, sequence_length):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.rnn = torch.nn.RNN(input_size=5, hidden_size=5, batch_first=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        x = x.view(x.size(0), self.sequence_length, self.input_size)\n",
    "        outputs, hidden = self.rnn(x,h_0)\n",
    "        return outputs.view(-1, num_classes)\n",
    "\n",
    "\n",
    "model = Model(num_classes, input_size, hidden_size, num_layers ,sequence_length)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimus = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1, loss: 1.689\nPredicted string:  oeoooo\nepoch: 11, loss: 1.448\nPredicted string:  llllll\nepoch: 21, loss: 1.314\nPredicted string:  llllll\nepoch: 31, loss: 1.202\nPredicted string:  illlll\nepoch: 41, loss: 1.115\nPredicted string:  ilelll\nepoch: 51, loss: 1.047\nPredicted string:  ilelll\nepoch: 61, loss: 0.993\nPredicted string:  ihelll\nepoch: 71, loss: 0.948\nPredicted string:  ihelll\nepoch: 81, loss: 0.909\nPredicted string:  ihelll\nepoch: 91, loss: 0.874\nPredicted string:  ihelll\nLearning finished!\n"
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    outputs = model(inputs)\n",
    "    optimus.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimus.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if epoch%10 == 0:\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.item()))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")\n",
    "  \n",
    "    \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3:\n",
    "\n",
    "* We will be doing the same experiment as above but rather than using one hot embedding we will be using `embedding layer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a project to convert hihell -> ihello\n",
    "\n",
    "# Data prepration\n",
    "\n",
    "\n",
    "x_data = [[0,1,0,2,3,3]] #hihell\n",
    "y_data = [1,0,2,3,3,4] #ihello\n",
    "\n",
    "\n",
    "inputs = torch.LongTensor(x_data)\n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embedding_size = 10\n",
    "num_classes =5\n",
    "input_size =5 # One-hot size\n",
    "hidden_size = 5 # output from the cell\n",
    "batch_size=1 # one sentence\n",
    "sequence_length=6\n",
    "num_layers=1 # one layer run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model(\n  (embedding): Embedding(5, 10)\n  (rnn): RNN(10, 5, batch_first=True)\n  (fc): Linear(in_features=5, out_features=5, bias=True)\n)\n"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # self.num_classes = num_classes\n",
    "        # self.input_size = input_size\n",
    "        # self.hidden_size = hidden_size\n",
    "        # self.num_layers = num_layers\n",
    "        # self.sequence_length = sequence_length\n",
    "\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=5, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0),hidden_size)\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(batch_size, sequence_length, -1)\n",
    "        outputs, hidden = self.rnn(emb,h_0)\n",
    "        return self.fc(outputs.view(-1, num_classes))\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimus = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1, loss: 1.808\nPredicted string:  oooooo\nepoch: 6, loss: 0.765\nPredicted string:  ehello\nepoch: 11, loss: 0.362\nPredicted string:  ihello\nepoch: 16, loss: 0.166\nPredicted string:  ihello\nepoch: 21, loss: 0.077\nPredicted string:  ihello\nepoch: 26, loss: 0.040\nPredicted string:  ihello\nepoch: 31, loss: 0.025\nPredicted string:  ihello\nepoch: 36, loss: 0.017\nPredicted string:  ihello\nepoch: 41, loss: 0.013\nPredicted string:  ihello\nepoch: 46, loss: 0.010\nPredicted string:  ihello\nepoch: 51, loss: 0.009\nPredicted string:  ihello\nepoch: 56, loss: 0.008\nPredicted string:  ihello\nepoch: 61, loss: 0.007\nPredicted string:  ihello\nepoch: 66, loss: 0.006\nPredicted string:  ihello\nepoch: 71, loss: 0.006\nPredicted string:  ihello\nepoch: 76, loss: 0.005\nPredicted string:  ihello\nepoch: 81, loss: 0.005\nPredicted string:  ihello\nepoch: 86, loss: 0.005\nPredicted string:  ihello\nepoch: 91, loss: 0.005\nPredicted string:  ihello\nepoch: 96, loss: 0.004\nPredicted string:  ihello\nLearning finished!\n"
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    outputs = model(inputs)\n",
    "    optimus.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimus.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if epoch%5 == 0:\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.item()))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}